%% Saved with string encoding Unicode (UTF-8) 

@book{olson2014ways,
  title={Ways of Knowing in HCI},
  author={Olson, Judith S and Kellogg, Wendy A},
  volume={2},
  year={2014},
  publisher={Springer}
}

@article{scheuerman2020:hcigenderguidelines,
  title={{HCI} guidelines for gender equity and inclusivity},
  author={Scheuerman, Morgan Klaus and Spiel, Katta and Haimson, Oliver L and Hamidi, Foad and Branham, Stacy M},
  journal={UMBC Faculty Collection},
  year={2020},
  url = {https://www.morgan-klaus.com/gender-guidelines.html}
}

@book{lazar2017research,
  title={Research methods in human-computer interaction},
  author={Lazar, Jonathan and Feng, Jinjuan Heidi and Hochheiser, Harry},
  year={2017},
  publisher={Morgan Kaufmann}
}

@inproceedings{carrol1999five,
  title = {Five Reasons for Scenario-Based Design},
  booktitle = {Proceedings of the 32nd Annual Hawaii International Conference on Systems Sciences. 1999. {{HICSS}}-32. {{Abstracts}} and {{CD}}-{{ROM}} of Full Papers},
  author = {Carrol, John M},
  year = {1999},
  pages = {11--pp},
  organization = {{IEEE}}
}


@book{preeceInteractionDesignHumancomputer2015,
  title = {Interaction Design: Beyond Human-Computer Interaction},
  shorttitle = {Interaction Design},
  author = {Preece, Jenny and Rogers, Yvonne and Sharp, Helen},
  year = {2015},
  edition = {Fourth edition},
  publisher = {{Wiley}},
  address = {{Chichester}},
  annotation = {OCLC: 903427599},
  isbn = {978-1-119-02075-2 978-1-119-06601-9 978-1-119-08879-0},
  language = {eng}
}



@article{gulliksenKeyPrinciplesUsercentred2003,
  title = {Key Principles for User-Centred Systems Design},
  author = {Gulliksen, Jan and G{\"o}ransson, Bengt and Boivie, Inger and Blomkvist, Stefan and Persson, Jenny and Cajander, {\AA}sa},
  year = {2003},
  month = nov,
  volume = {22},
  pages = {397--409},
  publisher = {{Taylor \& Francis}},
  issn = {0144-929X},
  doi = {10.1080/01449290310001624329},
  abstract = {The concept of user-centred systems design (UCSD) has no agreed upon definition. Consequently, there is a great variety in the ways it is applied, which may lead to poor quality and poor usability in the resulting systems, as well as misconceptions about the effectiveness of UCSD. The purpose of this paper is to propose a definition of UCSD. We have identified 12 key principles for the adoption of a user-centred development process, principles that are based on existing theory, as well as research in and experiences from a large number of software development projects. The initial set of principles were applied and evaluated in a case study and modified accordingly. These principles can be used to communicate the nature of UCSD, evaluate a development process or develop systems development processes that support a user-centred approach. We also suggest activity lists and some tools for applying UCSD.},
  annotation = {\_eprint: https://doi.org/10.1080/01449290310001624329},
  journal = {Behaviour \& Information Technology},
  number = {6}
}


@article{dis20109241,
  title = {9241-210: 2010. {{Ergonomics}} of Human System Interaction-{{Part}} 210: {{Human}}-Centred Design for Interactive Systems (Formerly Known as 13407)},
  author = {DIS, ISO},
  year = {2010},
  journal = {International Standardization Organization (ISO). Switzerland}
}


@mastersthesis{Uga1324610,
   author = {Uga, Brenda},
   institution = {Uppsala University, Department of Informatics and Media},
   pages = {77},
   school = {Uppsala University, Department of Informatics and Media},
   title = {Towards Trustworthy AI : A proposed set of design guidelines for understandable, trustworthy and actionable AI},
   keywords = {artificial intelligence, trust, design guidelines, research through design, human-computer interaction},
   abstract = {Artificial intelligence is used today in both everyday applications and specialised expert systems. In situations where relying on the output of the AI brings about the risk of negative consequences, it becomes important to understand why the AI system has produced its output. Previous research in human-computer trust has identified trust antecedents that contribute to formation of trust in an AI artifact, understanding of the system being one of them. In the context of Pipedrive, a sales management system, this thesis investigates how can AI predictions be designed as understandable and trustworthy, and by extension which explanatory aspects provide guidance towards actions to take, and which presentation formats support for- mation of trust. Using a research-through design approach, multiple designs for displaying AI predictions are explored for Pipedrive, leading to a proposal for a set of design guidelines that support understandability, trustworthiness and actionability of AI. Both the designs and the guidelines have been iteratively developed in collaboration with users and design practitioners. },
   year = {2019}
}

@mastersthesis{Joppien2020,
author = {Joppien, Lilli},
title = {Result-driven Interactive Visual Support of Parameter Selection for Dimensionality Reduction},
school = {Freie Universit\"at Berlin, Institute of Computer Science, Human-Centered Computing},
address = {Berlin},
year = {2020},
url = {http://dx.doi.org/10.17169/refubium-28005}
}






@article{contributionTypes2016,
author = {Wobbrock, Jacob O. and Kientz, Julie A.},
title = {Research Contributions in Human-Computer Interaction},
year = {2016},
issue_date = {May + June 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {1072-5520},
url = {https://doi.org/10.1145/2907069},
doi = {10.1145/2907069},
journal = {Interactions},
month = apr,
pages = {38â€“44},
numpages = {7}
}
