## Abstract

"[Use] data to make decisions" about system design (hci.1 p61)
"distinguish signal from noise" 


## in BA context
bc. exisitng users & workflows, common "first qualitative, then quantitaitve" no so strong,
als user base exisits to apply quantitative methods at the start

Triangulation of data (mutliple persons, multiple times) & methodological triangulation


## Data analysis factors
hci.1 until noted otherwise
### 1. descriptive - what is happening
- understandung users through demographic, socio-economic and behavioural factors
- good to vizualize
- establish KPIs

### 2. diagnostic - why is it happening
- interpretation of descriptiove data
- expose requirements of system
- user's skills in application domain & computer use

### 3. predictive - what will likely happen
- anticipate user's requirements -> plan before need is there

### 4. prescriptive - what to do
- combine factor 1 to 3 

# qualitative user research methods
## "fly-on-the-wall" observation (hci.1 p133f)
Spectate users without them knowing you are there.
Note: in this context difficult, as I can't and shouldn't spectate other people's screens without them knowing I look there.

Maybe derived method from this: analyze the questions they ask -> they indicate common problems

## moderated observation (hci.1 p135) 
[[Plan - Qualtitative User Research starting point]]
Main scope: create a scenario or catalyst for observing to have references.
Ask user to do a task, analyze and (optionally) also reflect work with user him/herself.

- create script beforehand to don't forget anything and have repeatability
- task should be common in their work and be done by as many people as possible in diffrent groups to have good comparability
- take notes during observation
- record if possible

## Contextual inquiry (VL2.3)
Base idea similar to moderated observation, but 
is more "learn from the workers" / observing the typical work a user does while moderated observation is focused on 

## user interviews (hci.1 p137)
Goal is to feel more like a natural conversation than strict Q->A flow.
- fit questions naturally into convo
- **Good opening question!!!**
- Questions should prompt user to elaborate and tell a story
- interviewer's main job is to listen and steer interviewee to follow 
- no need to go chronologically through all possible questions

#### Question types:
- open questions: can be answered in-depth, unique responses, including emotional component, interviewee can tell like a little story
- probing questions: dig into a detail the interviewee shared in a previous open question

#### what not to do
- multiple choice questions -> belong to survey
- "yes" / "no" questions -> -||-
- Leading questions (q's formulated so that the steer the user to an certain answer)

## user recording
- more meta-method, can be applied to all, by recording video
- -> not very applicable in our context


# quantitative user reserach methods
More scalable than qualitative methods.
Can support qualtitative methods greatly (example: see in user tracking some spend much more time than others -> interview why that is the case)

## Quantitative survey
?
## A/B testing
TODO

## Usability analytics
- track user interactions
- identify & diagnose issues
- gather demographic statistics, usage time statistics etc